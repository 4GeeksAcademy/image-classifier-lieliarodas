{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Image Classifier**\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Exploratory Data Analysis (EDA)**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "###  **Importing Libraries**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt \n",
                "import seaborn as sns\n",
                "import json\n",
                "import pickle\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.feature_selection import SelectKBest, f_regression\n",
                "import os\n",
                "import shutil"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "###  **Problem statement and data collection**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "import zipfile\n",
                "import io\n",
                "\n",
                "url = \"https://storage.googleapis.com/datascience-materials/dogs-vs-cats.zip\"\n",
                "response = requests.get(url)\n",
                "response.raise_for_status()\n",
                "\n",
                "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
                "    z.extractall(\"dogs-vs-cats\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "\n",
                "images_folder = \"../src/dogs-vs-cats/dogs-vs-cats/train\"\n",
                "source_folder = \"../data/processed\"\n",
                "cats_folder = \"../data/processed/cats\"\n",
                "dogs_folder = \"../data/processed/dogs\"\n",
                "\n",
                "# Crear carpetas si no existen\n",
                "os.makedirs(source_folder, exist_ok=True)\n",
                "os.makedirs(cats_folder, exist_ok=True)\n",
                "os.makedirs(dogs_folder, exist_ok=True)\n",
                "\n",
                "# Contadores para limitar 100 por clase\n",
                "cat_count = 0\n",
                "dog_count = 0\n",
                "max_images = 100  # máximo por clase\n",
                "\n",
                "for filename in os.listdir(images_folder):\n",
                "    file_path = os.path.join(images_folder, filename)\n",
                "    if os.path.isfile(file_path):\n",
                "        nombre = filename.lower()\n",
                "        if nombre.startswith(\"cat\") and cat_count < max_images:\n",
                "            shutil.copy(file_path, os.path.join(cats_folder, filename))\n",
                "            cat_count += 1\n",
                "        elif nombre.startswith(\"dog\") and dog_count < max_images:\n",
                "            shutil.copy(file_path, os.path.join(dogs_folder, filename))\n",
                "            dog_count += 1\n",
                "        \n",
                "        # Romper el loop si ya tenemos 100 de cada clase\n",
                "        if cat_count >= max_images and dog_count >= max_images:\n",
                "            break\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-08-20 18:19:43.677072: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-08-20 18:19:43.696281: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-08-20 18:19:44.867019: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2025-08-20 18:19:47.708736: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-08-20 18:19:47.710089: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
                    ]
                }
            ],
            "source": [
                "from keras.preprocessing import image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Damos etiquetas a las imagenes (Dario)\n",
                "def load_and_preprocess_images(data_dir, target_size=(224, 224)):\n",
                "    images = []\n",
                "    labels = []\n",
                "\n",
                "    for label in os.listdir(data_dir):\n",
                "        label_dir = os.path.join(data_dir, label)\n",
                "        if os.path.isdir(label_dir):\n",
                "            for filename in os.listdir(label_dir):\n",
                "                img_path = os.path.join(label_dir, filename)\n",
                "                try:\n",
                "                    img = image.load_img(img_path, target_size=target_size)\n",
                "                    img_array = image.img_to_array(img)\n",
                "                    img_array /= 255.0  # Normalizar los valores de píxeles\n",
                "                    images.append(img_array)\n",
                "                    # Asigna la etiqueta 0 para \"Cat\" y 1 para \"Dog\"\n",
                "                    if label == \"cats\":\n",
                "                        labels.append(0)\n",
                "                    elif label == \"dogs\":\n",
                "                        labels.append(1)\n",
                "                except Exception as e:\n",
                "                    print(f\"Error cargando la imagen {img_path}: {e}\")\n",
                "\n",
                "    return np.array(images), np.array(labels)\n",
                "\n",
                "\n",
                "images, labels = load_and_preprocess_images(\"../data/processed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Lo de arriba esta ok"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, Y_train, Y_test = train_test_split(images,labels, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ESTO NO VA O REVISAR QUE SIRVE\n",
                "\n",
                "import pandas as pd\n",
                "import shutil\n",
                "from sklearn.model_selection import train_test_split\n",
                "import os\n",
                "\n",
                "source_dir = \"../data/processed\"\n",
                "\n",
                "train_dir = \"../data/train\"\n",
                "test_dir = \"../data/test\"\n",
                "\n",
                "os.makedirs(train_dir, exist_ok=True)\n",
                "os.makedirs(test_dir, exist_ok=True)\n",
                "\n",
                "classes = [\"cats\", \"dogs\"]\n",
                "\n",
                "for cls in classes:\n",
                "    cls_path = os.path.join(source_dir, cls)\n",
                "    files = os.listdir(cls_path)\n",
                "    \n",
                "    train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
                "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
                "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
                "    \n",
                "    for f in train_files:\n",
                "        shutil.copy(os.path.join(cls_path, f), os.path.join(train_dir, cls, f))\n",
                "    \n",
                "    for f in test_files:\n",
                "        shutil.copy(os.path.join(cls_path, f), os.path.join(test_dir, cls, f))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "listdir: embedded null character in path",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m train_datagen = ImageDataGenerator()\n\u001b[32m      2\u001b[39m train_datagen_10_percent = ImageDataGenerator(rescale=\u001b[32m1\u001b[39m/\u001b[32m255.\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_data = \u001b[43mtrain_datagen_10_percent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                                                         \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategorical\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                                                         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                                                         \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m test_data = train_datagen_10_percent.flow_from_directory(X_test,Y_test,                                        \n\u001b[32m     11\u001b[39m                                                          class_mode=\u001b[33m'\u001b[39m\u001b[33mcategorical\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m                                                          batch_size=\u001b[32m32\u001b[39m,\n\u001b[32m     13\u001b[39m                                                          shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1138\u001b[39m, in \u001b[36mImageDataGenerator.flow_from_directory\u001b[39m\u001b[34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[39m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflow_from_directory\u001b[39m(\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1122\u001b[39m     directory,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1136\u001b[39m     keep_aspect_ratio=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1137\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:453\u001b[39m, in \u001b[36mDirectoryIterator.__init__\u001b[39m\u001b[34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m    452\u001b[39m     classes = []\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os.listdir(directory)):\n\u001b[32m    454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(os.path.join(directory, subdir)):\n\u001b[32m    455\u001b[39m             classes.append(subdir)\n",
                        "\u001b[31mValueError\u001b[39m: listdir: embedded null character in path"
                    ]
                }
            ],
            "source": [
                "train_datagen = ImageDataGenerator()\n",
                "train_datagen_10_percent = ImageDataGenerator(rescale=1/255.)\n",
                "\n",
                "\n",
                "train_data = train_datagen_10_percent.flow_from_directory(X_train, Y_train,\n",
                "                                                         class_mode='categorical',\n",
                "                                                         batch_size=32,\n",
                "                                                         shuffle=True)\n",
                "\n",
                "test_data = train_datagen_10_percent.flow_from_directory(X_test,Y_test,                                        \n",
                "                                                         class_mode='categorical',\n",
                "                                                         batch_size=32,\n",
                "                                                         shuffle=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
                        "2025-08-20 18:25:21.667820: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
                    ]
                }
            ],
            "source": [
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "\n",
                "# Mover los datos por las capas densas\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 2, activation = \"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# definir el \n",
                "\n",
                "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
                "\n",
                "model.compile(optimizer = \"adam\", loss = SparseCategoricalCrossentropy(from_logits = True), metrics = [\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#entrenamos el modelo\n",
                "model.fit(X_train, y_train, epochs = 150, batch_size = 10)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
